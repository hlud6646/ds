{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Combining Training and Test data sets.\n",
    "A standard scenario is the following.\n",
    "In the Titanic problem, the training data contains the feature 'Survived'.  The Test data obviously does not contain this feature.  This should be the only difference in the shape of the two data frames. Rather than working with each frame seperately (to fill missing values etc), it's much cleaner to join them, tidy in one sweep and then seperate before loading the model.\n",
    "\n",
    "Not only is it cleaner, philosophically training and testing data should be considered the same in every way (how else can you build an unbiased model?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./input/titanic/train.csv')\n",
    "test  = pd.read_csv('./input/titanic/test.csv')\n",
    "\n",
    "print(\"Before joining:\")\n",
    "print('train shape:', train.shape)\n",
    "print('test shape: ', test.shape, '\\n')\n",
    "\n",
    "# Save this column for later.\n",
    "survived = train['Survived']\n",
    "train = train.drop('Survived', axis=1)\n",
    "\n",
    "# Join frames.\n",
    "titanic = pd.concat([train, test], axis=0, sort=False)\n",
    "\n",
    "print(\"After joining:\")\n",
    "print(\"titanic shape: \", titanic.shape, '\\n')\n",
    "\n",
    "# Go and tidy the data...\n",
    "# ...\n",
    "\n",
    "# Split it back to train and test.\n",
    "train = titanic[0:891]\n",
    "test  = titanic[891: 1310]\n",
    "\n",
    "print(\"After Splitting:\")\n",
    "print('train shape:', train.shape)\n",
    "print('test shape: ', test.shape, '\\n')\n",
    "\n",
    "# Prepare for loading into model\n",
    "x_train = train\n",
    "y_train = survived\n",
    "x_test  = test\n",
    "\n",
    "# model = SomeModel()\n",
    "# model.fit(x_train, y_train)\n",
    "# model.score(x_train, y_train)\n",
    "# y_prediction = model.predict(x_test) \n",
    "# etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Conforming to Submission Format.\n",
    "An easy way to conform to the submission format is to load the sample submission and replace the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample submission.\n",
    "# submission = pd.read_csv('./output/sample_submission.csv')\n",
    "\n",
    "# Replace target with the model's predictions.\n",
    "# submission['target'] = model.predict(test_vectors)\n",
    "\n",
    "# Save submission.\n",
    "# submission.to_csv('./output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Models Relying on Random State.\n",
    "According to the *Into to Machine Learning* tutorial on Kaggle, it is best practice to declare the seed when instantiating a model if applicable.  This allows for repeatable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Categorical Variables\n",
    "For ordinal categorical variables (e.g. 'Never' < 'Sometimes' < 'Always') map the categories to the sequence $ 1 < 2 < 3 < ...$\n",
    "For nominal categorical variables (e.g. 'Red', 'Green') use One-hot encoding (so long as there are not too many categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One liner with inbuilt function.\n",
    "import pandas as pd\n",
    "df = df.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glossary\n",
    "*Imputation* 'The assignment of a value to something by inference from the value of the products or processes to which it contributes.' - Oxford.  E.g. replacing a missing value by the mean of that values column.\n",
    "\n",
    "*One-hot encoding* The creation of a boolean feature for each possible value of a nominal categorical feature.\n",
    "\n",
    "*Fold* A subset of the training data used to cross-validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
