{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) Naming Conventions.\n",
    "- `full_data` refers to a dataframe containing the full training set, i.e. the result of something like `df = pd.read_csv('/blah/train.csv)`.\n",
    "- `X, y, valid_X, valid_y` refer to the training and validation input and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Combining Training and Test data sets.\n",
    "\n",
    "<font color=red> Warning: This is probably actually really bad form because it will aggresively encourage train-test contamination. </font>\n",
    "\n",
    "A standard scenario is the following.\n",
    "In the Titanic problem, the training data contains the feature 'Survived'.  The Test data obviously does not contain this feature.  This should be the only difference in the shape of the two data frames. Rather than working with each frame seperately (to fill missing values etc), it's much cleaner to join them, tidy in one sweep and then seperate before loading the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./input/titanic/train.csv')\n",
    "test  = pd.read_csv('./input/titanic/test.csv')\n",
    "\n",
    "print(\"Before joining:\")\n",
    "print('train shape:', train.shape)\n",
    "print('test shape: ', test.shape, '\\n')\n",
    "\n",
    "# Save this column for later.\n",
    "survived = train['Survived']\n",
    "train = train.drop('Survived', axis=1)\n",
    "\n",
    "# Join frames.\n",
    "titanic = pd.concat([train, test], axis=0, sort=False)\n",
    "\n",
    "print(\"After joining:\")\n",
    "print(\"titanic shape: \", titanic.shape, '\\n')\n",
    "\n",
    "# Go and tidy the data...\n",
    "# ...\n",
    "\n",
    "# Split it back to train and test.\n",
    "train = titanic[0:891]\n",
    "test  = titanic[891: 1310]\n",
    "\n",
    "print(\"After Splitting:\")\n",
    "print('train shape:', train.shape)\n",
    "print('test shape: ', test.shape, '\\n')\n",
    "\n",
    "# Prepare for loading into model\n",
    "x_train = train\n",
    "y_train = survived\n",
    "x_test  = test\n",
    "\n",
    "# model = SomeModel()\n",
    "# model.fit(x_train, y_train)\n",
    "# model.score(x_train, y_train)\n",
    "# y_prediction = model.predict(x_test) \n",
    "# etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Conforming to Submission Format.\n",
    "An easy way to conform to the submission format is to load the sample submission and replace the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample submission.\n",
    "# submission = pd.read_csv('./output/sample_submission.csv')\n",
    "\n",
    "# Replace target with the model's predictions.\n",
    "# submission['target'] = model.predict(test_vectors)\n",
    "\n",
    "# Save submission.\n",
    "# submission.to_csv('./output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Models Relying on Random State.\n",
    "According to the *Into to Machine Learning* tutorial on Kaggle, it is best practice to declare the seed when instantiating a model if applicable.  This allows for repeatable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Random Utililty Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Add a suffix to every column name.\n",
    "df.add_suffix(\"_normalized\")\n",
    "\n",
    "# One-hot encoding for all categorical variables.\n",
    "pd.get_dummies(df)\n",
    "\n",
    "# Train-test split.\n",
    "# Be aware of 'shuffle' parameter.\n",
    "from sklean.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Count frequencies of a category\n",
    "df['feature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glossary\n",
    "*Imputation* 'The assignment of a value to something by inference from the value of the products or processes to which it contributes.' - Oxford.  E.g. replacing a missing value by the mean of that values column.\n",
    "\n",
    "*One-hot encoding* The creation of a boolean feature for each possible value of a nominal categorical feature.\n",
    "\n",
    "*Fold* A subset of the training data used to cross-validate.\n",
    "\n",
    "A *dense layer* in a neural network is one in which each neuron recieves input from every neuron in the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
